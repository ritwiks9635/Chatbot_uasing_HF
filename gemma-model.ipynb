{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1245709,"sourceType":"datasetVersion","datasetId":715041},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth', 256)\nimport re\n# from https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora\n\n# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U keras-nlp\n!pip install -q -U keras>=3\n\nimport os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-09T15:09:49.124220Z","iopub.execute_input":"2024-07-09T15:09:49.124869Z","iopub.status.idle":"2024-07-09T15:10:19.695037Z","shell.execute_reply.started":"2024-07-09T15:09:49.124836Z","shell.execute_reply":"2024-07-09T15:10:19.693866Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nimport keras_nlp\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:12:54.334387Z","iopub.execute_input":"2024-07-09T15:12:54.335414Z","iopub.status.idle":"2024-07-09T15:14:25.654810Z","shell.execute_reply.started":"2024-07-09T15:12:54.335376Z","shell.execute_reply":"2024-07-09T15:14:25.653975Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-09 15:12:57.889933: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-09 15:12:57.890086: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-09 15:12:58.033276: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttaching 'model.safetensors' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.safetensors.index.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.safetensors' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.safetensors.index.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.safetensors' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.safetensors.index.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(gemma_lm.generate(\"What is Matplotlib?\", max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:14:35.224716Z","iopub.execute_input":"2024-07-09T15:14:35.225981Z","iopub.status.idle":"2024-07-09T15:14:53.539566Z","shell.execute_reply.started":"2024-07-09T15:14:35.225941Z","shell.execute_reply":"2024-07-09T15:14:53.538455Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"What is Matplotlib?\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to create graphs, charts, and other types of visualizations.\n\nMatplotlib is a Python library for creating 2D plots. It is used to\n","output_type":"stream"}]},{"cell_type":"code","source":"#file = open('../input/simple-dialogs-for-chatbot/dialogs.txt','r').read()\ndataset='''What is data science?\\tData science is an interdisciplinary field that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\\n\nWhat are the key steps involved in the data science process?\\tThe key steps in the data science process include problem definition, data collection, data preparation, exploratory data analysis, modeling, evaluation, and deployment.\\n \nWhat is the difference between supervised and unsupervised learning?\\tSupervised learning involves training a model on labeled data, where the algorithm learns to predict the output from input data. Unsupervised learning involves training a model on unlabeled data to discover patterns or groupings within the data.\\n \nWhat is overfitting in machine learning?\\tOverfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data rather than the underlying patterns. This can result in poor performance when the model is applied to new, unseen data.\\n \nWhat evaluation metrics can be used to assess the performance of a classification model?\\tCommon evaluation metrics for classification models include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC).\\n \nWhat is cross-validation and why is it used in machine learning?\\tCross-validation is a technique used to assess the performance of a machine learning model by training and evaluating it multiple times on different subsets of the data. It helps to ensure that the model's performance is robust and not overly dependent on a particular subset of the data.\\n \nWhat is the purpose of feature engineering in machine learning?\\tFeature engineering involves transforming raw data into a format that is suitable for training machine learning models. It aims to extract relevant information from the data and create informative features that improve the performance of the models.\\n \nWhat are some common algorithms used in machine learning?\\tSome common algorithms used in machine learning include linear regression, logistic regression, decision trees, random forests, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks.\\n \nWhat is the curse of dimensionality in machine learning?\\tThe curse of dimensionality refers to the problems that arise when working with high-dimensional data. As the number of features or dimensions increases, the amount of data required to effectively cover the feature space grows exponentially, making it difficult to train accurate models.\\n \nWhat is the difference between data mining and machine learning?\\tData mining is the process of discovering patterns, trends, and insights from large datasets, often using techniques such as clustering, association rule mining, and anomaly detection. Machine learning, on the other hand, is a subset of data mining that focuses on building predictive models from data using algorithms and statistical methods.\\n \nWhat are some common data preprocessing techniques used in data science?\\tCommon data preprocessing techniques include data cleaning (handling missing values, removing duplicates), data transformation (scaling, normalization), feature extraction, and feature selection.\\n \nWhat libraries are commonly used for data analysis and manipulation in Python?\\tCommonly used libraries for data analysis and manipulation in Python include Pandas, NumPy, and SciPy.\\n\nWhat is the purpose of the Pandas library in Python?\\tThe Pandas library is used for data manipulation and analysis in Python. It provides data structures and functions for efficiently handling structured data, such as dataframes for tabular data and series for one-dimensional data.\\n \nWhat is a dataframe in Pandas?\\tA dataframe in Pandas is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled rows and columns. It is similar to a spreadsheet or SQL table and can store data of different types (e.g., integers, floats, strings) in each column.\\n \nHow can you read a CSV file into a Pandas dataframe in Python?\\tYou can read a CSV file into a Pandas dataframe using the read_csv() function. For example: df = pd.read_csv('filename.csv')\\n \nHow can you display the first few rows of a Pandas dataframe?\\tYou can display the first few rows of a Pandas dataframe using the head() function. For example: df.head()\\n\nHow can you select specific columns from a Pandas dataframe?\\tYou can select specific columns from a Pandas dataframe by passing a list of column names to the square brackets indexing operator. For example: df[['column1', 'column2']]\\n \nHow can you filter rows of a Pandas dataframe based on a condition?\\tYou can filter rows of a Pandas dataframe based on a condition by passing the condition as a boolean expression to the square brackets indexing operator. For example: df[df['column'] > 10]\\n \nWhat is NumPy and what is it used for in Python?\\tNumPy is a Python library for numerical computing. It provides support for multidimensional arrays, matrices, mathematical functions, and random number generation, making it useful for scientific and mathematical applications.\\n \nWhat is the purpose of arrays in NumPy?\\tArrays in NumPy are used to represent and manipulate numerical data efficiently. They provide a homogeneous data container that can store elements of the same data type and support vectorized operations, enabling fast and efficient computation.\\n \nHow can you create an array in NumPy?\\tYou can create an array in NumPy using the array() function by passing a Python list or tuple containing the elements of the array. For example: np.array([1, 2, 3])\\n \nHow can you perform element-wise operations on NumPy arrays?\\tYou can perform element-wise operations on NumPy arrays by applying mathematical functions or operators directly to the arrays. For example: np.array([1, 2, 3]) + np.array([4, 5, 6])\\n \nHow can you reshape a NumPy array?\\tYou can reshape a NumPy array using the reshape() function by specifying the desired shape as a tuple of dimensions. For example: np.array([1, 2, 3, 4, 5, 6]).reshape(2, 3)\\n \nHow can you concatenate two NumPy arrays?\\tYou can concatenate two NumPy arrays along a specified axis using the concatenate() function. For example: np.concatenate([array1, array2], axis=0)\\n \nWhat is SciPy and what is it used for in Python?\\tSciPy is a Python library for scientific computing and technical computing. It provides modules for optimization, integration, interpolation, linear algebra, and many other numerical tasks, making it useful for scientific and engineering applications.\\n \nHow can you integrate a mathematical function numerically using SciPy?\\tYou can integrate a mathematical function numerically using the quad() function from the scipy.integrate module. For example: from scipy.integrate import quad result, error = quad(func, a, b)\\n \nHow can you fit a curve to data points using SciPy?\\tYou can fit a curve to data points using the curve_fit() function from the scipy.optimize module. For example: from scipy.optimize import curve_fit params, covariance = curve_fit(func, xdata, ydata)\\n \nWhat is Matplotlib and what is it used for in Python?\\tMatplotlib is a Python library for creating static, interactive, and animated visualizations. It provides functions for generating plots, histograms, scatter plots, and many other types of graphs, making it useful for data analysis and presentation.\\n \nHow can you create a line plot in Matplotlib?\\tYou can create a line plot in Matplotlib using the plot() function by passing the x and y coordinates of the data points. For example: plt.plot(x, y)\\n\nHow can you customize the appearance of a plot in Matplotlib?\\tYou can customize the appearance of a plot in Matplotlib by using various functions and parameters to modify aspects such as the plot type, color, linestyle, marker style, axis labels, title, and legend.\\n \nHow can you save a plot as an image file in Matplotlib?\\tYou can save a plot as an image file in Matplotlib using the savefig() function by specifying the desired file format (e.g., PNG, JPEG, PDF) and filename. For example: plt.savefig('filename.png')\\n \nWhat is Seaborn and what is it used for in Python?\\tSeaborn is a Python library for statistical data visualization based on Matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics, making it useful for data exploration and analysis.\\n \nHow can you create a histogram in Seaborn?\\tYou can create a histogram in Seaborn using the distplot() function by passing the data to be plotted as input. For example: sns.distplot(data)\\n \nHow can you create a scatter plot in Seaborn?\\tYou can create a scatter plot in Seaborn using the scatterplot() function by specifying the x and y variables to be plotted. For example: sns.scatterplot(x='x_variable', y='y_variable', data=data)\\n \nHow can you create a box plot in Seaborn?\\tYou can create a box plot in Seaborn using the boxplot() function by specifying the data and grouping variables. For example: sns.boxplot(x='group_variable', y='data_variable', data=data)\\n \nHow can you create a pair plot in Seaborn?\\tYou can create a pair plot in Seaborn using the pairplot() function by passing the dataframe containing the variables to be plotted. For example: sns.pairplot(data)\\n \nWhat is scikit-learn and what is it used for in Python?\\tScikit-learn is a Python library for machine learning and statistical modeling. It provides a wide range of algorithms and tools for tasks such as classification, regression, clustering, dimensionality reduction, and model selection, making it useful for building and evaluating machine learning models.\\n \nHow can you split a dataset into training and test sets in scikit-learn?\\tYou can split a dataset into training and test sets using the train_test_split() function from the sklearn.model_selection module. For example: from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\nWhat is linear regression and how can you implement it in scikit-learn?\\tLinear regression is a supervised learning algorithm used for predicting a continuous target variable based on one or more input features. You can implement linear regression in scikit-learn using the LinearRegression class. For example: from sklearn.linear_model import LinearRegression model = LinearRegression() model.fit(X_train, y_train)\\n \nWhat is logistic regression and how can you implement it in scikit-learn?\\tLogistic regression is a supervised learning algorithm used for binary classification tasks. You can implement logistic regression in scikit-learn using the LogisticRegression class. For example: from sklearn.linear_model import LogisticRegression model = LogisticRegression() model.fit(X_train, y_train)\\n\nHow can you evaluate the performance of a machine learning model in scikit-learn?\\tYou can evaluate the performance of a machine learning model in scikit-learn using various metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC). For example: from sklearn.metrics import accuracy_score y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred)\\n\nHow can you perform hyperparameter tuning for a machine learning model in scikit-learn?\\tYou can perform hyperparameter tuning for a machine learning model in scikit-learn using techniques such as grid search and random search. For example: from sklearn.model_selection import GridSearchCV param_grid = {'param1': [value1, value2], 'param2': [value3, value4]} grid_search = GridSearchCV(estimator, param_grid, cv=5) grid_search.fit(X_train, y_train)\\n\nHow can you integrate a mathematical function numerically using SciPy?\\tYou can integrate a mathematical function numerically using the quad() function from the scipy.integrate module. For example: from scipy.integrate import quad result, error = quad(func, a, b)\\n How can you fit a curve to data points using SciPy?\\tYou can fit a curve to data points using the curve_fit() function from the scipy.optimize module. For example: from scipy.optimize import curve_fit params, covariance = curve_fit(func, xdata, ydata)\\n What is Matplotlib and what is it used for in Python?\\tMatplotlib is a Python library for creating static, interactive, and animated visualizations. It provides functions for generating plots, histograms, scatter plots, and many other types of graphs, making it useful for data analysis and presentation.\\n How can you create a line plot in Matplotlib?\\tYou can create a line plot in Matplotlib using the plot() function by passing the x and y coordinates of the data points. For example: plt.plot(x, y)\\n How can you customize the appearance of a plot in Matplotlib?\\tYou can customize the appearance of a plot in Matplotlib by using various functions and parameters to modify aspects such as the plot type, color, linestyle, marker style, axis labels, title, and legend.\\n How can you save a plot as an image file in Matplotlib?\\tYou can save a plot as an image file in Matplotlib using the savefig() function by specifying the desired file format (e.g., PNG, JPEG, PDF) and filename. For example: plt.savefig('filename.png')\\n What is Seaborn and what is it used for in Python?\\tSeaborn is a Python library for statistical data visualization based on Matplotlib. It provides a high-level interface for creating attractive and informative statistical graphics, making it useful for data exploration and analysis.\\n How can you create a histogram in Seaborn?\\tYou can create a histogram in Seaborn using the distplot() function by passing the data to be plotted as input. For example: sns.distplot(data)\\n How can you create a scatter plot in Seaborn?\\tYou can create a scatter plot in Seaborn using the scatterplot() function by specifying the x and y variables to be plotted. For example: sns.scatterplot(x='x_variable', y='y_variable', data=data)\\n How can you create a box plot in Seaborn?\\tYou can create a box plot in Seaborn using the boxplot() function by specifying the data and grouping variables. For example: sns.boxplot(x='group_variable', y='data_variable', data=data)\\n How can you create a pair plot in Seaborn?\\tYou can create a pair plot in Seaborn using the pairplot() function by passing the dataframe containing the variables to be plotted. For example: sns.pairplot(data)\\n What is scikit-learn and what is it used for in Python?\\tScikit-learn is a Python library for machine learning and statistical modeling. It provides a wide range of algorithms and tools for tasks such as classification, regression, clustering, dimensionality reduction, and model selection, making it useful for building and evaluating machine learning models.\\n How can you split a dataset into training and test sets in scikit-learn?\\tYou can split a dataset into training and test sets using the train_test_split() function from the sklearn.model_selection module. For example: from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n What is linear regression and how can you implement it in scikit-learn?\\tLinear regression is a supervised learning algorithm used for predicting a continuous target variable based on one or more input features. You can implement linear regression in scikit-learn using the LinearRegression class. For example: from sklearn.linear_model import LinearRegression model = LinearRegression() model.fit(X_train, y_train)\\n What is logistic regression and how can you implement it in scikit-learn?\\tLogistic regression is a supervised learning algorithm used for binary classification tasks. You can implement logistic regression in scikit-learn using the LogisticRegression class. For example: from sklearn.linear_model import LogisticRegression model = LogisticRegression() model.fit(X_train, y_train)\\n How can you evaluate the performance of a machine learning model in scikit-learn?\\tYou can evaluate the performance of a machine learning model in scikit-learn using various metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC). For example: from sklearn.metrics import accuracy_score y_pred = model.predict(X_test) accuracy = accuracy_score(y_test, y_pred)\\n How can you perform hyperparameter tuning for a machine learning model in scikit-learn?\\tYou can perform hyperparameter tuning for a machine learning model in scikit-learn using techniques such as grid search and random search. For example: from sklearn.model_selection import GridSearchCV param_grid = {'param1': [value1, value2], 'param2': [value3, value4]} grid_search = GridSearchCV(estimator, param_grid, cv=5) grid_search.fit(X_train, y_train)\\n '''","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-09T15:15:19.876472Z","iopub.execute_input":"2024-07-09T15:15:19.876846Z","iopub.status.idle":"2024-07-09T15:15:19.894668Z","shell.execute_reply.started":"2024-07-09T15:15:19.876814Z","shell.execute_reply":"2024-07-09T15:15:19.893692Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"qna_list = {'Questions':[],'Answers':[]}\nfor f in dataset.split('\\n'):\n    if len(f.split('\\t'))==2:\n        qna_list['Questions'].append(f.split('\\t')[0])\n        qna_list['Answers'].append(f.split('\\t')[1])\n\ndata=pd.DataFrame(qna_list)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:15:29.834520Z","iopub.execute_input":"2024-07-09T15:15:29.835157Z","iopub.status.idle":"2024-07-09T15:15:29.844038Z","shell.execute_reply.started":"2024-07-09T15:15:29.835124Z","shell.execute_reply":"2024-07-09T15:15:29.843057Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:15:49.844285Z","iopub.execute_input":"2024-07-09T15:15:49.845162Z","iopub.status.idle":"2024-07-09T15:15:49.862287Z","shell.execute_reply.started":"2024-07-09T15:15:49.845128Z","shell.execute_reply":"2024-07-09T15:15:49.861292Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                                                  Questions  \\\n0                                                                     What is data science?   \n1                              What are the key steps involved in the data science process?   \n2                      What is the difference between supervised and unsupervised learning?   \n3                                                  What is overfitting in machine learning?   \n4  What evaluation metrics can be used to assess the performance of a classification model?   \n5                          What is cross-validation and why is it used in machine learning?   \n6                           What is the purpose of feature engineering in machine learning?   \n7                                 What are some common algorithms used in machine learning?   \n8                                  What is the curse of dimensionality in machine learning?   \n9                          What is the difference between data mining and machine learning?   \n\n                                                                                                                                                                                                                                                           Answers  \n0                                                                                        Data science is an interdisciplinary field that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data.  \n1                                                                                        The key steps in the data science process include problem definition, data collection, data preparation, exploratory data analysis, modeling, evaluation, and deployment.  \n2            Supervised learning involves training a model on labeled data, where the algorithm learns to predict the output from input data. Unsupervised learning involves training a model on unlabeled data to discover patterns or groupings within the data.  \n3                    Overfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data rather than the underlying patterns. This can result in poor performance when the model is applied to new, unseen data.  \n4                                                                                                                           Common evaluation metrics for classification models include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC).  \n5  Cross-validation is a technique used to assess the performance of a machine learning model by training and evaluating it multiple times on different subsets of the data. It helps to ensure that the model's performance is robust and not overly dependent...  \n6        Feature engineering involves transforming raw data into a format that is suitable for training machine learning models. It aims to extract relevant information from the data and create informative features that improve the performance of the models.  \n7                                                   Some common algorithms used in machine learning include linear regression, logistic regression, decision trees, random forests, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks.  \n8  The curse of dimensionality refers to the problems that arise when working with high-dimensional data. As the number of features or dimensions increases, the amount of data required to effectively cover the feature space grows exponentially, making it ...  \n9  Data mining is the process of discovering patterns, trends, and insights from large datasets, often using techniques such as clustering, association rule mining, and anomaly detection. Machine learning, on the other hand, is a subset of data mining tha...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is data science?</td>\n      <td>Data science is an interdisciplinary field that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What are the key steps involved in the data science process?</td>\n      <td>The key steps in the data science process include problem definition, data collection, data preparation, exploratory data analysis, modeling, evaluation, and deployment.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the difference between supervised and unsupervised learning?</td>\n      <td>Supervised learning involves training a model on labeled data, where the algorithm learns to predict the output from input data. Unsupervised learning involves training a model on unlabeled data to discover patterns or groupings within the data.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is overfitting in machine learning?</td>\n      <td>Overfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data rather than the underlying patterns. This can result in poor performance when the model is applied to new, unseen data.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What evaluation metrics can be used to assess the performance of a classification model?</td>\n      <td>Common evaluation metrics for classification models include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC).</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What is cross-validation and why is it used in machine learning?</td>\n      <td>Cross-validation is a technique used to assess the performance of a machine learning model by training and evaluating it multiple times on different subsets of the data. It helps to ensure that the model's performance is robust and not overly dependent...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>What is the purpose of feature engineering in machine learning?</td>\n      <td>Feature engineering involves transforming raw data into a format that is suitable for training machine learning models. It aims to extract relevant information from the data and create informative features that improve the performance of the models.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>What are some common algorithms used in machine learning?</td>\n      <td>Some common algorithms used in machine learning include linear regression, logistic regression, decision trees, random forests, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>What is the curse of dimensionality in machine learning?</td>\n      <td>The curse of dimensionality refers to the problems that arise when working with high-dimensional data. As the number of features or dimensions increases, the amount of data required to effectively cover the feature space grows exponentially, making it ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>What is the difference between data mining and machine learning?</td>\n      <td>Data mining is the process of discovering patterns, trends, and insights from large datasets, often using techniques such as clustering, association rule mining, and anomaly detection. Machine learning, on the other hand, is a subset of data mining tha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Cleaning Data","metadata":{}},{"cell_type":"code","source":"# remove any HTML/Markdown tags\ndata['Questions'] = data['Questions'].str.replace(r'<[^<>]*>', '', regex=True)\n# remove any newline\ndata['Questions'] = data['Questions'].str.replace(r'\\n',' ', regex=True)\n# remove any @user tags\ndata['Questions'] = data['Questions'].str.replace(r'(?<=\\s)@[\\w]+|(?<=^)@[\\w]+', '', regex=True)\n\n# repeat same cleaning for the Response column as well\ndata['Answers'] = data['Answers'].str.replace(r'<[^<>]*>', '', regex=True)\ndata['Answers'] = data['Answers'].str.replace(r'\\n',' ', regex=True)\ndata['Answers'] = data['Answers'].str.replace(r'(?<=\\s)@[\\w]+|(?<=^)@[\\w]+', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:01.514759Z","iopub.execute_input":"2024-07-09T15:16:01.515163Z","iopub.status.idle":"2024-07-09T15:16:01.531232Z","shell.execute_reply.started":"2024-07-09T15:16:01.515132Z","shell.execute_reply":"2024-07-09T15:16:01.530257Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:08.889817Z","iopub.execute_input":"2024-07-09T15:16:08.890529Z","iopub.status.idle":"2024-07-09T15:16:08.900653Z","shell.execute_reply.started":"2024-07-09T15:16:08.890494Z","shell.execute_reply":"2024-07-09T15:16:08.899575Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                                                  Questions  \\\n0                                                                     What is data science?   \n1                              What are the key steps involved in the data science process?   \n2                      What is the difference between supervised and unsupervised learning?   \n3                                                  What is overfitting in machine learning?   \n4  What evaluation metrics can be used to assess the performance of a classification model?   \n5                          What is cross-validation and why is it used in machine learning?   \n6                           What is the purpose of feature engineering in machine learning?   \n7                                 What are some common algorithms used in machine learning?   \n8                                  What is the curse of dimensionality in machine learning?   \n9                          What is the difference between data mining and machine learning?   \n\n                                                                                                                                                                                                                                                           Answers  \n0                                                                                        Data science is an interdisciplinary field that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data.  \n1                                                                                        The key steps in the data science process include problem definition, data collection, data preparation, exploratory data analysis, modeling, evaluation, and deployment.  \n2            Supervised learning involves training a model on labeled data, where the algorithm learns to predict the output from input data. Unsupervised learning involves training a model on unlabeled data to discover patterns or groupings within the data.  \n3                    Overfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data rather than the underlying patterns. This can result in poor performance when the model is applied to new, unseen data.  \n4                                                                                                                           Common evaluation metrics for classification models include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC).  \n5  Cross-validation is a technique used to assess the performance of a machine learning model by training and evaluating it multiple times on different subsets of the data. It helps to ensure that the model's performance is robust and not overly dependent...  \n6        Feature engineering involves transforming raw data into a format that is suitable for training machine learning models. It aims to extract relevant information from the data and create informative features that improve the performance of the models.  \n7                                                   Some common algorithms used in machine learning include linear regression, logistic regression, decision trees, random forests, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks.  \n8  The curse of dimensionality refers to the problems that arise when working with high-dimensional data. As the number of features or dimensions increases, the amount of data required to effectively cover the feature space grows exponentially, making it ...  \n9  Data mining is the process of discovering patterns, trends, and insights from large datasets, often using techniques such as clustering, association rule mining, and anomaly detection. Machine learning, on the other hand, is a subset of data mining tha...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Questions</th>\n      <th>Answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is data science?</td>\n      <td>Data science is an interdisciplinary field that uses scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What are the key steps involved in the data science process?</td>\n      <td>The key steps in the data science process include problem definition, data collection, data preparation, exploratory data analysis, modeling, evaluation, and deployment.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the difference between supervised and unsupervised learning?</td>\n      <td>Supervised learning involves training a model on labeled data, where the algorithm learns to predict the output from input data. Unsupervised learning involves training a model on unlabeled data to discover patterns or groupings within the data.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is overfitting in machine learning?</td>\n      <td>Overfitting occurs when a model learns the training data too well, capturing noise or random fluctuations in the data rather than the underlying patterns. This can result in poor performance when the model is applied to new, unseen data.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What evaluation metrics can be used to assess the performance of a classification model?</td>\n      <td>Common evaluation metrics for classification models include accuracy, precision, recall, F1-score, and area under the ROC curve (AUC).</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What is cross-validation and why is it used in machine learning?</td>\n      <td>Cross-validation is a technique used to assess the performance of a machine learning model by training and evaluating it multiple times on different subsets of the data. It helps to ensure that the model's performance is robust and not overly dependent...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>What is the purpose of feature engineering in machine learning?</td>\n      <td>Feature engineering involves transforming raw data into a format that is suitable for training machine learning models. It aims to extract relevant information from the data and create informative features that improve the performance of the models.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>What are some common algorithms used in machine learning?</td>\n      <td>Some common algorithms used in machine learning include linear regression, logistic regression, decision trees, random forests, support vector machines (SVM), k-nearest neighbors (KNN), and neural networks.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>What is the curse of dimensionality in machine learning?</td>\n      <td>The curse of dimensionality refers to the problems that arise when working with high-dimensional data. As the number of features or dimensions increases, the amount of data required to effectively cover the feature space grows exponentially, making it ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>What is the difference between data mining and machine learning?</td>\n      <td>Data mining is the process of discovering patterns, trends, and insights from large datasets, often using techniques such as clustering, association rule mining, and anomaly detection. Machine learning, on the other hand, is a subset of data mining tha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset = []\n    \nfor index, row in data.iterrows():\n    instruction, response = row['Questions'], row['Answers']\n    template = (f\"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\")\n    dataset.append(template)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:14.885055Z","iopub.execute_input":"2024-07-09T15:16:14.885406Z","iopub.status.idle":"2024-07-09T15:16:14.894928Z","shell.execute_reply.started":"2024-07-09T15:16:14.885381Z","shell.execute_reply":"2024-07-09T15:16:14.894067Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Using LoRA fine-tuned model","metadata":{}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 64.\ngemma_lm.backbone.enable_lora(rank=64)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:33.266009Z","iopub.execute_input":"2024-07-09T15:16:33.266951Z","iopub.status.idle":"2024-07-09T15:16:33.700195Z","shell.execute_reply.started":"2024-07-09T15:16:33.266912Z","shell.execute_reply":"2024-07-09T15:16:33.699379Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # Limit the input sequence length to 512 (to control memory usage).\n# gemma_lm.preprocessor.sequence_length = 512\n# # Use AdamW (a common optimizer for transformer models).\n# optimizer = keras.optimizers.AdamW(\n#     learning_rate=5e-5,\n#     weight_decay=0.01,\n# )\n# # Exclude layernorm and bias terms from decay.\n# optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\n# gemma_lm.compile(\n#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n#     optimizer=optimizer,\n#     weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n# )","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:38.834339Z","iopub.execute_input":"2024-07-09T15:16:38.835113Z","iopub.status.idle":"2024-07-09T15:16:38.839596Z","shell.execute_reply.started":"2024-07-09T15:16:38.835079Z","shell.execute_reply":"2024-07-09T15:16:38.838555Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"gemma_lm.preprocessor.sequence_length = 314\n# Use AdamW (a common optimizer for transformer models).\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    beta_1=0.9,          # Adjust beta_1 parameter\n    beta_2=0.999         # Adjust beta_2 parameter\n)\n# Exclude layernorm and bias terms from decay.\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:43.374064Z","iopub.execute_input":"2024-07-09T15:16:43.374739Z","iopub.status.idle":"2024-07-09T15:16:43.445598Z","shell.execute_reply.started":"2024-07-09T15:16:43.374708Z","shell.execute_reply":"2024-07-09T15:16:43.444741Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"gemma_lm.fit(dataset, epochs=25, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:16:48.884668Z","iopub.execute_input":"2024-07-09T15:16:48.885061Z","iopub.status.idle":"2024-07-09T15:29:42.894210Z","shell.execute_reply.started":"2024-07-09T15:16:48.885016Z","shell.execute_reply":"2024-07-09T15:29:42.893256Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 496ms/step - loss: 0.3063 - sparse_categorical_accuracy: 0.6420\nEpoch 2/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 489ms/step - loss: 0.1774 - sparse_categorical_accuracy: 0.7748\nEpoch 3/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 489ms/step - loss: 0.1488 - sparse_categorical_accuracy: 0.8104\nEpoch 4/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.8569\nEpoch 5/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.8881\nEpoch 6/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 706ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9221\nEpoch 7/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9409\nEpoch 8/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 491ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9405\nEpoch 9/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 491ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9403\nEpoch 10/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 491ms/step - loss: 0.0608 - sparse_categorical_accuracy: 0.9418\nEpoch 11/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0559 - sparse_categorical_accuracy: 0.9473\nEpoch 12/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 706ms/step - loss: 0.0528 - sparse_categorical_accuracy: 0.9472\nEpoch 13/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 489ms/step - loss: 0.0506 - sparse_categorical_accuracy: 0.9470\nEpoch 14/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9472\nEpoch 15/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9472\nEpoch 16/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0454 - sparse_categorical_accuracy: 0.9505\nEpoch 17/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0439 - sparse_categorical_accuracy: 0.9476\nEpoch 18/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0404 - sparse_categorical_accuracy: 0.9476\nEpoch 19/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9488\nEpoch 20/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9498\nEpoch 21/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 489ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9666\nEpoch 22/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9653\nEpoch 23/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9660\nEpoch 24/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 490ms/step - loss: 0.0195 - sparse_categorical_accuracy: 0.9653\nEpoch 25/25\n\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 489ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9666\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b3bbc0b0370>"},"metadata":{}}]},{"cell_type":"code","source":"print(gemma_lm.generate(\"What is Matplotlib?\", max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:29:53.468998Z","iopub.execute_input":"2024-07-09T15:29:53.469667Z","iopub.status.idle":"2024-07-09T15:30:07.100679Z","shell.execute_reply.started":"2024-07-09T15:29:53.469632Z","shell.execute_reply":"2024-07-09T15:30:07.099711Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"What is Matplotlib?\n\nMatplotlib is a Python library for creating static, interactive, and animated visualizations. You can use Matplotlib to create a variety of graphics, such as plots, histograms, and scatter plots, making it useful for data analysis and presentation.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gemma_lm.generate(\"What is Machine Learning?\", max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-07-09T15:30:55.355261Z","iopub.execute_input":"2024-07-09T15:30:55.355660Z","iopub.status.idle":"2024-07-09T15:30:56.470068Z","shell.execute_reply.started":"2024-07-09T15:30:55.355627Z","shell.execute_reply":"2024-07-09T15:30:56.469044Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"What is Machine Learning?\n\nMachine learning is an artificial intelligence (AI) field that provides instructions (GORITHMS) for training the model with data to carry out tasks without being explicitly programmed.\n","output_type":"stream"}]}]}