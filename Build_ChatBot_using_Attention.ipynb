{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwiks9635/Chatbot_uasing_HF/blob/main/Build_ChatBot_using_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Build ChatBot using Attention**\n",
        "\n",
        "[Dataset](https://www.kaggle.com/datasets/saurabhprajapat/chatbot-training-dataset)\n",
        "\n",
        "[Dataset2](https://www.kaggle.com/datasets/projjal1/human-conversation-training-data)\n",
        "\n",
        "[Dataset3](https://www.kaggle.com/datasets/grafstor/simple-dialogs-for-chatbot)\n",
        "\n",
        "[Embedding](https://www.kaggle.com/datasets/pkugoodspeed/nlpword2vecembeddingspretrained)"
      ],
      "metadata": {
        "id": "HAiS1sjcDEha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "data = \"/content/https:/www.kaggle.com/datasets/kausr25/chatterbotenglish/chatterbotenglish.zip\"\n",
        "with ZipFile(data,\"r\") as z:\n",
        "  z.extractall(\"Chatbot_data/data\")\n",
        "  print(\"the data has been extracted \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbgBM6UuJzon",
        "outputId": "ecd22946-b759-47b5-cfd3-e05bc3fe5d32"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the data has been extracted \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import yaml\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "-T2JcGKTKCGu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/Chatbot_data/data'\n",
        "files_list = os.listdir(dir_path + os.sep)\n",
        "\n",
        "questions = []\n",
        "answers = []\n",
        "for filepath in files_list:\n",
        "    stream = open(dir_path + os.sep + filepath, \"rb\")\n",
        "    docs = yaml.safe_load(stream)\n",
        "    conversations = docs['conversations']\n",
        "    for con in conversations:\n",
        "        if len(con) > 2 :\n",
        "            questions.append(con[0])\n",
        "            replies = con[1 :]\n",
        "            ans = ''\n",
        "            for rep in replies:\n",
        "                ans += ' ' + rep\n",
        "            answers.append(ans)\n",
        "        elif len(con) > 1:\n",
        "            questions.append(con[0])\n",
        "            answers.append(con[1])\n",
        "\n",
        "answers_with_tags = []\n",
        "for i in range(len(answers)):\n",
        "    if type(answers[i]) == str:\n",
        "        answers_with_tags.append(answers[i])\n",
        "    else:\n",
        "        questions.pop(i)\n",
        "\n",
        "answers = []\n",
        "for i in range(len(answers_with_tags)) :\n",
        "    answers.append('' + answers_with_tags[i] + '')"
      ],
      "metadata": {
        "id": "AP-W1BvxJuCD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/chatbot dataset.txt\") as f:\n",
        "    for line in f:\n",
        "        split_lines = line.split(\"\\t\")\n",
        "        if len(split_lines[0]) > 2:\n",
        "            questions.append(split_lines[0])\n",
        "            answers.append(split_lines[1])"
      ],
      "metadata": {
        "id": "nzbxZaX3VHiU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/dialogs.txt\") as f:\n",
        "    for line in f:\n",
        "        split_lines = line.split(\"\\t\")\n",
        "        if len(split_lines[0]) > 2:\n",
        "            questions.append(split_lines[0])\n",
        "            answers.append(split_lines[1])\n",
        "print(len(answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl2AJy_8YDjO",
        "outputId": "745b0b64-6719-49e1-b375-64e3cdbc3d73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"query\" : questions, \"result\" : answers})\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GkqSKjaVMn_2",
        "outputId": "59f71013-76d9-437d-dea2-d67949e9a750"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  query  \\\n",
              "4849    that's a good question. maybe it's not old age.   \n",
              "4850                              are you right-handed?   \n",
              "4851                                  yes. all my life.   \n",
              "4852  you're wearing out your right hand. stop using...   \n",
              "4853        but i do all my writing with my right hand.   \n",
              "\n",
              "                                                 result  \n",
              "4849                            are you right-handed?\\n  \n",
              "4850                                yes. all my life.\\n  \n",
              "4851  you're wearing out your right hand. stop using...  \n",
              "4852      but i do all my writing with my right hand.\\n  \n",
              "4853  start typing instead. that way your left hand ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4f523ab-d2ec-4bdb-a369-6b4d209e7c7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4849</th>\n",
              "      <td>that's a good question. maybe it's not old age.</td>\n",
              "      <td>are you right-handed?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4850</th>\n",
              "      <td>are you right-handed?</td>\n",
              "      <td>yes. all my life.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851</th>\n",
              "      <td>yes. all my life.</td>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "      <td>but i do all my writing with my right hand.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "      <td>start typing instead. that way your left hand ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4f523ab-d2ec-4bdb-a369-6b4d209e7c7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4f523ab-d2ec-4bdb-a369-6b4d209e7c7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4f523ab-d2ec-4bdb-a369-6b4d209e7c7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1cea13df-9830-4087-aa0a-805ac042aef3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1cea13df-9830-4087-aa0a-805ac042aef3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1cea13df-9830-4087-aa0a-805ac042aef3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"are you right-handed?\",\n          \"but i do all my writing with my right hand.\",\n          \"yes. all my life.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"yes. all my life.\\n\",\n          \"start typing instead. that way your left hand will do half the work.\",\n          \"you're wearing out your right hand. stop using it so much.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcXVJrA2f4Vf",
        "outputId": "5ca33d7e-05dc-4c13-e1df-c124596f9ee9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "query     0\n",
              "result    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace  = True)"
      ],
      "metadata": {
        "id": "8qBeGHargNF3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFO_DAQbgO3F",
        "outputId": "c919ef02-e577-4596-9be0-3bb174726bba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4851, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = set(string.punctuation)\n",
        "remove_digits = str.maketrans('', '', string.digits)"
      ],
      "metadata": {
        "id": "00KV5VonQseB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_questions_sentences(sent):\n",
        "    '''Function to preprocess English Sentence'''\n",
        "    sent = sent.lower()\n",
        "    sent = sent.replace(\"'\", '')  # Changed .sub() to .replace()\n",
        "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
        "    sent = sent.translate(remove_digits)\n",
        "\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(\" +\", \" \", sent)\n",
        "    return sent\n",
        "\n",
        "def preprocess_answer_sentence(sent):\n",
        "    if isinstance(sent, str):\n",
        "        sent = sent.lower()\n",
        "        sent = sent.replace(\"'\", '')\n",
        "        sent = ''.join(ch for ch in sent if ch not in exclude)\n",
        "        sent = sent.translate(remove_digits)\n",
        "        sent = sent.strip()\n",
        "        sent = re.sub(\" +\", \" \", sent)\n",
        "        sent = \"startseq \" + sent + \" endseq\"\n",
        "        return sent\n",
        "    else:\n",
        "\n",
        "        return sent"
      ],
      "metadata": {
        "id": "amQ9ERCzYshg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['query'] = df['query'].apply(preprocess_questions_sentences)\n",
        "df['result'] = df['result'].apply(preprocess_answer_sentence)"
      ],
      "metadata": {
        "id": "r-ZmctUEp5g1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ThsptOhjqR-5",
        "outputId": "a21392b2-bad0-4ee9-f65c-69a803b6adf8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          query                                             result\n",
              "0  you get paid           startseq i have no need for money endseq\n",
              "1  stock market                  startseq buy low sell high endseq\n",
              "2  stock market                 startseq invest in yourself endseq\n",
              "3  stock market  startseq why not just take everything to a cas...\n",
              "4  stock market  startseq i wouldnt recommend buying on the mar..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d39b3008-73f3-4aee-81a6-b826c402668e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you get paid</td>\n",
              "      <td>startseq i have no need for money endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stock market</td>\n",
              "      <td>startseq buy low sell high endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stock market</td>\n",
              "      <td>startseq invest in yourself endseq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stock market</td>\n",
              "      <td>startseq why not just take everything to a cas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stock market</td>\n",
              "      <td>startseq i wouldnt recommend buying on the mar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d39b3008-73f3-4aee-81a6-b826c402668e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d39b3008-73f3-4aee-81a6-b826c402668e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d39b3008-73f3-4aee-81a6-b826c402668e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6e514ba-54eb-4d97-a2cb-684d0b5a2bac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6e514ba-54eb-4d97-a2cb-684d0b5a2bac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6e514ba-54eb-4d97-a2cb-684d0b5a2bac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4851,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3899,\n        \"samples\": [\n          \"ive got to go\",\n          \"ive actually been busy lately\",\n          \"how angry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4042,\n        \"samples\": [\n          \"startseq im going to clean it endseq\",\n          \"startseq you are a cheat endseq\",\n          \"startseq you have a lot of plants endseq\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 30\n",
        "\n",
        "ques_sentences = df['query'].tolist()\n",
        "ans_sentences = df['result'].tolist()\n",
        "\n",
        "n = len(ques_sentences)\n",
        "split_index1 = int(0.95 * n)\n",
        "split_index2 = int(0.98 * n)\n",
        "\n",
        "train_ques_sents = ques_sentences[:split_index2]\n",
        "test_ques_sents = ques_sentences[split_index2:]\n",
        "\n",
        "train_ans_sents = ans_sentences[:split_index2]\n",
        "test_ans_sents = ans_sentences[split_index2:]"
      ],
      "metadata": {
        "id": "YAKc-ZZDqZL7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ques_sents = [str(sent) for sent in train_ques_sents]\n",
        "train_ans_sents = [str(sent) for sent in train_ans_sents]\n",
        "\n",
        "# Tokenize question sentences\n",
        "ques_tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "ques_tokenizer.fit_on_texts(train_ques_sents)\n",
        "ques_vocab_size = len(ques_tokenizer.word_index) + 1\n",
        "\n",
        "# Tokenize answer sentences\n",
        "ans_tokenizer = Tokenizer()\n",
        "ans_tokenizer.fit_on_texts(train_ans_sents)\n",
        "ans_vocab_size = len(ans_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "MQgzAk87xDQd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Question Vocab Size: {ques_vocab_size}\\nAnswer Vocab Size: {ans_vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZTaieOCxPqT",
        "outputId": "b9fad068-bad9-4e03-8c12-9f4c6acb3239"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Vocab Size: 2558\n",
            "Answer Vocab Size: 3341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ques_sequence = ques_tokenizer.texts_to_sequences(train_ques_sents)\n",
        "ans_sequence = ans_tokenizer.texts_to_sequences(train_ans_sents)\n",
        "\n",
        "ques_padding = pad_sequences(ques_sequence, maxlen = max_length, padding = \"post\")\n",
        "ans_padding = pad_sequences(ans_sequence, maxlen = max_length, padding = \"post\")"
      ],
      "metadata": {
        "id": "v1f_lHMuSRB8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((ques_padding[:split_index1], ans_padding[:split_index1]))\n",
        "train_dataset = train_dataset.shuffle(buffer_size = split_index1).batch(32, drop_remainder = True)\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((ques_padding[split_index1:], ans_padding[split_index1:]))\n",
        "valid_dataset = valid_dataset.batch(32, drop_remainder = True)"
      ],
      "metadata": {
        "id": "VDifh6NqimB7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dict = {}\n",
        "\n",
        "# Open the GloVe embeddings file\n",
        "with open('/content/glove.6B.100d.txt', 'r', encoding='utf-8') as file:\n",
        "    # Iterate over each line in the file\n",
        "    for line in tqdm(file, desc='Loading Glove Embedding'):\n",
        "        # Split the line into words and their corresponding embedding vectors\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "\n",
        "        # Store the word and its embedding vector in the dictionary\n",
        "        embeddings_dict[word] = coefs\n",
        "\n",
        "# Create embedding matrices\n",
        "ques_embedding_matrix = np.zeros((ques_vocab_size, 100))\n",
        "ans_embedding_matrix = np.zeros((ans_vocab_size, 100))\n",
        "\n",
        "# Populate embedding matrices with GloVe vectors for words in the vocabulary\n",
        "for word, index in ques_tokenizer.word_index.items():\n",
        "    if word in embeddings_dict:\n",
        "        ques_embedding_matrix[index] = embeddings_dict[word]\n",
        "\n",
        "for word, index in ans_tokenizer.word_index.items():\n",
        "    if word in embeddings_dict:\n",
        "        ans_embedding_matrix[index] = embeddings_dict[word]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx9waQdVjaYa",
        "outputId": "72568c7e-02e1-47f4-e451-c4579727565e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Glove Embedding: 400000it [00:14, 27855.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_obj = keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_obj(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype = loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "1VX9oKEcjR2R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Attention Mechanism**\n",
        "\n",
        "Attention mechanism are a type of neural network layer that can be add to deep learning models. They allow the model to focus on specific parts of the input. This weights is typically based on the relevence of each part of the input to the task at hand.Similarly for the task of Neural Text Generation.\n",
        "\n",
        "\n",
        "**Additive Attention:** This mechanism refers to Dzmitry Bahdanau's work title \"Neural Machine Translation by Jointly Learning to Align and Translate\". This, this tecnique is also known as Bahdanau attention. The additive attention is implemented as follows\n",
        "\n",
        "- Addition of weeighted Decoder hidden state and Encoder hidden states\n",
        "\n",
        "- Tanh function is applied over this addition\n",
        "-  Output of step 2 is passed through another linear layer\n",
        "- Softmax function is applied to calculate the normalized allignment attention scores\n",
        "- Attention scores are applied to the encoder hidden state to indentify the importance of each source word with respect to the next output word\n",
        "\n",
        "\n",
        "**Multiplicative Attention:** This method is proposed by Thang Luong in the work title 'Effective Approaches to Attention-based Neural Machine Translation'. It is build on top of additive attention (a.k.a Bahdanau attention). there are three scoring functions that we can choose from - dot, general , concat,(we have used dot in our code)\n",
        "\n",
        "- Matrix multiplication perfomed between Encoder hidden states and Deocder hidden state\n",
        "-  Softmax function is applied t calculate the normalized allignment attention scores\n",
        "- Attention scores are applied to the Encoder hidden states to indentify the importance of each source word with respect to the next output word/"
      ],
      "metadata": {
        "id": "_0d4CdXO2SXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = layers.Dense(units)\n",
        "        self.W2 = layers.Dense(units)\n",
        "        self.V = layers.Dense(1)\n",
        "\n",
        "\n",
        "    def call(self, s_hidden, h_hidden):\n",
        "        s_hidden = tf.expand_dims(s_hidden, axis =1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(s_hidden) + self.W2(h_hidden)))\n",
        "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "        context_vector = attention_weights * h_hidden\n",
        "        context_vector = tf.expand_dims(tf.reduce_sum(context_vector, axis = 1), axis = 1)\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "W9ibvjtYnlS5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class LuongAttention\n",
        "class  LuongAttention(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(LuongAttention, self).__init__()\n",
        "\n",
        "    def call(self, s_hidden, h_hidden):\n",
        "        score = tf.matmul(h_hidden, s_hidden, transpose_b =True)\n",
        "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
        "        context_vector = attention_weights * h_hidden\n",
        "        context_vector = tf.expand_dims(tf.reduce_sum(context_vector, axis =1), axis =1)\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "TsJoGDNdn1uA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Sequence2Sequence Model With Attention Layer**\n",
        "\n",
        "**Encoder**\n",
        "\n",
        "- It uses RNN layer and converts the input words to corresponding hidden vectors. Each vector represents the current word and the contex of the word. The encoder takes the input sequence, one token at a time, and uses an to update it's hidden state, which summarizes the information inthe input sequence. The finel hidden state (state_h in the code) of the encoder is then passed as the context vector to the decoder. Since we are using Bidirectional LSTM as our RNN, we will get 2 hidden ecoder states (forward_state_h and backward_state_h) and 2 cell states (forward_state_c and bacword_state_c). We concatenate them into one hidden and cell state (state_h, and state-c in the code)\n",
        "\n",
        "**Decoder**\n",
        "\n",
        "- It takes as input the hidden vector generated by the encoder, it's own hidden states, and the current word to preduce the next hidden vector and finally predict the next word. In out case, since it is a Bi LSTM, we also take the cell sate along with the hidden state. **When using the attention layer we first calculate the attention context vector by applying attention mechanism on the decoder hidden state and the encoder hidden states, once the context vector is preduced it is concatenated wirh the current word embeding and passed to the decoder to predict the next word. The decoder useds this new context vector and an initial hidden state to generate the output sequence, one token at a time. At each time step, the decoder uses the current hidden state, the attention alligned context vector, and the previous output token to generate a probability distribution over the possible next tokens. The token with the highest probability is then chosen as the output, and the process continues until the end of the output sequence (end) is reached."
      ],
      "metadata": {
        "id": "0bXd-N_k1l1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dims, units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = layers.Embedding(vocab_size, embedding_dims, mask_zero=True)\n",
        "        self.lstm = layers.Bidirectional(layers.LSTM(units, return_sequences=True, return_state=True))\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        enc_output, forward_h, forward_c, backward_h, backward_c = self.lstm(x)\n",
        "        state_h = layers.Concatenate()([forward_h, backward_h])\n",
        "        state_c = layers.Concatenate()([forward_c, backward_c])\n",
        "\n",
        "        return enc_output, state_h, state_c"
      ],
      "metadata": {
        "id": "tx-vog6jo6hS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dims, units, use_additive=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.units = units\n",
        "        self.embedding = layers.Embedding(vocab_size, embedding_dims, mask_zero=True)\n",
        "        self.lstm = layers.LSTM(units, return_sequences=True, return_state=True)\n",
        "        self.attention = BahdanauAttention(units) if use_additive else LuongAttention(units)\n",
        "        self.fc = layers.TimeDistributed(layers.Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "    def call(self, x, enc_output, state_h, state_c):\n",
        "        x = self.embedding(x)\n",
        "        context_vector, attn_weights = self.attention(state_h, enc_output)\n",
        "        context_vector = layers.Concatenate(axis=-1)([context_vector, x])\n",
        "        dec_output, dec_h, dec_c = self.lstm(context_vector, initial_state=[state_h, state_c])\n",
        "        output = self.fc(dec_output)\n",
        "\n",
        "        return output, dec_h, dec_c, attn_weights"
      ],
      "metadata": {
        "id": "jl93bmR2pQpa"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(ques_vocab_size, 512, 256)\n",
        "decoder = Decoder(ans_vocab_size, 512, 512)"
      ],
      "metadata": {
        "id": "t5o6qiZcqMam"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "M9UzghXlqSwi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Teacher Forcing**"
      ],
      "metadata": {
        "id": "F-UkB_AQ1Z_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    loss_value = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoder_output, state_h, state_c  = encoder(x)\n",
        "        dec_input = tf.expand_dims(y[:, 0], 1)\n",
        "\n",
        "        for i in range(1, y.shape[1]):\n",
        "            dec_output, state_h, state_c, attn_w = decoder(dec_input, encoder_output, state_h, state_c)\n",
        "            loss_value += loss_function(y[:, i], dec_output[:, 0, :])\n",
        "            dec_input = tf.expand_dims(y[:, i], 1)\n",
        "\n",
        "    batch_loss = (loss_value / int(y.shape[1]))\n",
        "    weights = encoder.trainable_variables + decoder.trainable_variables\n",
        "    grads = tape.gradient(loss_value, weights)\n",
        "    optimizer.apply_gradients(zip(grads, weights))\n",
        "    return batch_loss\n",
        "\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    loss_value = 0\n",
        "    encoder_output, state_h, state_c  = encoder(x)\n",
        "    dec_input = tf.expand_dims(y[:, 0], 1)\n",
        "\n",
        "    for i in range(1, y.shape[1]):\n",
        "        dec_output, state_h, state_c, attn_w = decoder(dec_input, encoder_output, state_h, state_c)\n",
        "        loss_value += loss_function(y[:, i], dec_output[:, 0, :])\n",
        "        dec_input = tf.expand_dims(y[:, i], 1)\n",
        "\n",
        "    batch_loss = (loss_value / int(y.shape[1]))\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "y_FpR-MPqXn2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "\n",
        "epochs = 10\n",
        "train_steps = np.sum([1 for i in train_dataset])\n",
        "val_steps = np.sum([1 for i in valid_dataset])  # Calculate number of validation steps\n",
        "metrics_names = ['train_loss', 'val_loss']  # Include 'val_loss' in metrics_names\n",
        "mon_val_loss = np.inf\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch: \", epoch+1)\n",
        "    training_loss = []\n",
        "    validation_loss = []\n",
        "    progBar = Progbar(train_steps, stateful_metrics=metrics_names)\n",
        "\n",
        "    # Training loop\n",
        "    for step, (X_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        train_loss = train_step(X_batch_train, y_batch_train)\n",
        "        training_loss.append(train_loss)\n",
        "        values = [('train_loss', train_loss)]\n",
        "        progBar.update(step, values=values)\n",
        "\n",
        "    avg_train_loss = np.average(training_loss)\n",
        "    values = [('train_loss', avg_train_loss)]\n",
        "    progBar.update(step, values)\n",
        "\n",
        "    # Validation loop\n",
        "    for step, (X_batch_val, y_batch_val) in enumerate(valid_dataset):\n",
        "        val_loss = test_step(X_batch_val, y_batch_val)\n",
        "        validation_loss.append(val_loss)\n",
        "\n",
        "    avg_val_loss = np.average(validation_loss)\n",
        "    values.append(('val_loss', avg_val_loss))\n",
        "    progBar.update(train_steps, values=values, finalize=True)\n",
        "\n",
        "    # Check if validation loss improved\n",
        "    if avg_val_loss < mon_val_loss:\n",
        "        encoder.save_weights(\"encoder.weights.h5\")\n",
        "        decoder.save_weights(\"decoder.weights.h5\")\n",
        "        print(f\"Model loss improved from {mon_val_loss:.5f} to {avg_val_loss:.5f} Checkpoint Created: encoder.weights.h5, decoder.weights.h5\")\n",
        "\n",
        "    mon_val_loss = avg_val_loss"
      ],
      "metadata": {
        "id": "c_ewafmpq98Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.save_weights(\" /content/encoder.weights.h5\")\n",
        "decoder.save_weights( \"/content/decoder.weights.h5\")"
      ],
      "metadata": {
        "id": "GbZcgbuJxsJS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.load_weights('/content/encoder.weights.h5')\n",
        "decoder.load_weights('/content/decoder.weights.h5')"
      ],
      "metadata": {
        "id": "t5H_1eT1yHRj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentence(en_input):\n",
        "    eng_sequence = ques_tokenizer.texts_to_sequences([en_input])\n",
        "    en_input = pad_sequences(eng_sequence, maxlen=max_length, padding='post')\n",
        "    hidden_state, next_h, next_c = encoder(en_input)\n",
        "    attn_plot = []\n",
        "\n",
        "    curr_token = np.zeros((1,1))\n",
        "    curr_token[0,0] = ans_tokenizer.word_index['startseq']\n",
        "    pred_sentence = ''\n",
        "\n",
        "    for i in range(max_length):\n",
        "        output, next_h, next_c, attn_w = decoder(curr_token, hidden_state, next_h, next_c)\n",
        "        attn_plot.append(attn_w.numpy().reshape(-1,))\n",
        "        next_token = np.argmax(output[:, 0, :], axis=1)[0]\n",
        "        next_word = ans_tokenizer.index_word[next_token]\n",
        "        if next_word == 'endseq':\n",
        "            break\n",
        "        else:\n",
        "            pred_sentence += ' ' + next_word\n",
        "            curr_token[0,0] = next_token\n",
        "\n",
        "    return pred_sentence.strip()"
      ],
      "metadata": {
        "id": "_CyyfHGJy23_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    # Exit loop if user enters 'exit'\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Get response from the model\n",
        "    response = predict_sentence(user_input)\n",
        "\n",
        "    print(\"User Input:\", user_input)\n",
        "    print(\"Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dZSgtzHzR3_",
        "outputId": "304d2acd-f6dd-4085-d489-64ac723d69f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: What is ai\n",
            "User Input: What is ai\n",
            "Chatbot: ai is the field of science which concerns itself with the branch of engineering and science devoted to constructing machines in surgery etc\n",
            "You: Whai is stock\n",
            "User Input: Whai is stock\n",
            "Chatbot: im not sure how much is an stock\n",
            "You: Hi\n",
            "User Input: Hi\n",
            "Chatbot: hello\n",
            "You: how are you\n",
            "User Input: how are you\n",
            "Chatbot: i am not into violence\n",
            "You: I am fine and you\n",
            "User Input: I am fine and you\n",
            "Chatbot: i dont know you knew\n",
            "You: You get paid\n",
            "User Input: You get paid\n",
            "Chatbot: i certainly do\n",
            "You: Stock market\n",
            "User Input: Stock market\n",
            "Chatbot: mutual funds might be better unless you are wealthy\n",
            "You: Stock merket\n",
            "User Input: Stock merket\n",
            "Chatbot: you can be better unless you\n",
            "You: Exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}